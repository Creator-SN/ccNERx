{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate data/ontonotes5/train.json etag: 100%|██████████| 16.3M/16.3M [00:00<00:00, 349MB/s]\n",
      "calculate data/ontonotes5/dev.json etag: 100%|██████████| 2.01M/2.01M [00:00<00:00, 354MB/s]\n",
      "calculate data/ontonotes5/test.json etag: 100%|██████████| 2.00M/2.00M [00:00<00:00, 344MB/s]\n",
      "calculate data/ontonotes5/ontonotes5_labels.txt etag: 100%|██████████| 614/614 [00:00<00:00, 1.21MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"use_gpu\": false,\n",
      "    \"loader_name\": \"le_loader\",\n",
      "    \"model_name\": \"LEBert\",\n",
      "    \"lstm_crf_model_file\": \"/home/lpc/repos/ccNERx/save_model/ontonotes5/lstm_crf/lstm_crf_13823.pth\",\n",
      "    \"bert_model_file\": \"/home/lpc/repos/ccNERx/save_model/ontonotes5/LEBert/LEBert_13823.pth\",\n",
      "    \"hidden_dim\": 300,\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"bert_config_file_name\": \"./model/chinese_wwm_ext/config.json\",\n",
      "    \"tag_file\": \"data/ontonotes5/ontonotes5_labels.txt\",\n",
      "    \"padding_length\": 512,\n",
      "    \"num_gpus\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ]\n",
      "}\n",
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 512,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"data/ontonotes5/train.json\",\n",
      "    \"eval_file\": \"data/ontonotes5/dev.json\",\n",
      "    \"test_file\": \"data/ontonotes5/test.json\",\n",
      "    \"tag_file\": \"data/ontonotes5/ontonotes5_labels.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": true,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": true,\n",
      "    \"task_name\": \"super_predict_model\"\n",
      "}\n",
      "load cached ./temp/476f67c99ca56e0b89056f7ef462d2ac-4_ce61c1b52833ada8b5f3ec3bfaf00bb7_a837adf46522abcbc2acc8c9f9ea7d60_6aa179f1cd1584c53fef6462f9143bca/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "count line size data/ontonotes5/ontonotes5_labels.txt: 74L [00:00, 485725.35L/s]\n",
      "build line mapper: 74L [00:00, 520769.29L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 74/74 [00:00<00:00, 18729.09it/s]\n",
      "load vocab from list: 100%|██████████| 73/73 [00:00<00:00, 440552.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/476f67c99ca56e0b89056f7ef462d2ac-4_ce61c1b52833ada8b5f3ec3bfaf00bb7_a837adf46522abcbc2acc8c9f9ea7d60_6aa179f1cd1584c53fef6462f9143bca/1000000/matched_words\n",
      "load cached ./temp/476f67c99ca56e0b89056f7ef462d2ac-4_ce61c1b52833ada8b5f3ec3bfaf00bb7_a837adf46522abcbc2acc8c9f9ea7d60_6aa179f1cd1584c53fef6462f9143bca/1000000/word_vocab\n",
      "load cached ./temp/476f67c99ca56e0b89056f7ef462d2ac-4_ce61c1b52833ada8b5f3ec3bfaf00bb7_a837adf46522abcbc2acc8c9f9ea7d60_6aa179f1cd1584c53fef6462f9143bca/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/yfy/miniconda3/envs/ccner/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1642: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    }
   ],
   "source": [
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': 'data/ontonotes5/train.json',\n",
    "    'eval_file': 'data/ontonotes5/dev.json',\n",
    "    'test_file': 'data/ontonotes5/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/ontonotes5/ontonotes5_labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'le_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'super_predict_model'\n",
    "}\n",
    "\n",
    "from CC.predicter import NERPredict\n",
    "import json\n",
    "\n",
    "# 使用了预训练模型\n",
    "args[\"lstm_crf_model_file\"] = \"/home/lpc/repos/ccNERx/save_model/ontonotes5/lstm_crf/lstm_crf_13823.pth\"\n",
    "args[\"bert_model_file\"] = \"/home/lpc/repos/ccNERx/save_model/ontonotes5/LEBert/LEBert_13823.pth\"\n",
    "predict = NERPredict(**args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['九', '十', '年', '代'], ['B-DATE', 'I-DATE', 'I-DATE', 'E-DATE'])]\n",
      "QUANTITY 0.0\n",
      "LOC 0.0\n",
      "LAW 0.0\n",
      "CARDINAL 0.0\n",
      "PRODUCT 0.0\n",
      "GPE 0.0\n",
      "DATE 0.999959\n",
      "ORDINAL 0.0\n",
      "MONEY 0.0\n",
      "ORG 0.0\n",
      "NORP 0.0\n",
      "EVENT 0.0\n",
      "PERSON 0.0\n",
      "PERCENT 0.0\n",
      "FAC 0.0\n",
      "WORK_OF_ART 0.0\n",
      "TIME 6e-06\n",
      "LANGUAGE 0.0\n",
      "O 3.5e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "text = \"九十年代\"\n",
    "print(predict([text]))\n",
    "hidden_state,masks = predict.p([text])\n",
    "\n",
    "crf = predict.birnncrf.crf\n",
    "features,masks = predict.birnncrf._BiRnnCrf__build_features(hidden_state,masks)\n",
    "\n",
    "features = crf.fc(features)\n",
    "L = features.size(1)\n",
    "masks_ = masks[:, :L].float()\n",
    "\n",
    "tag_vocab = predict.dataloader()[\"tag_vocab\"]\n",
    "labels = tag_vocab.item2idx.keys()\n",
    "labels_set = set()\n",
    "for label in labels:\n",
    "    labels_set.add(label.split(\"-\")[-1])\n",
    "\n",
    "from CC.loaders.utils.label import get_labels\n",
    "# 构造标签集合\n",
    "\n",
    "ans = []\n",
    "for label in labels_set:\n",
    "    paths = []\n",
    "    if label != \"O\":\n",
    "        paths = [\"O\"] + get_labels(label,len(text),has_end=False,middle_symbol=\"I\")\n",
    "    paths += [\"O\"] * (150-len(paths))\n",
    "    # print(paths)\n",
    "    paths = torch.tensor(tag_vocab.token2id(paths),dtype=torch.long).unsqueeze(0)\n",
    "    ans.append(crf._CRF__score_sentence(features,paths[:, :L].long(),masks_).item())\n",
    "    # print(crf.loss(features,paths,masks))\n",
    "soft = torch.nn.Softmax(-1)\n",
    "ans = soft(torch.tensor(ans))\n",
    "for label,ans in zip(labels_set,ans):\n",
    "    print(label,round(ans.item(),6))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9627571863819468058fb8a0d45e3ad069ccb5b5ca291368ca8fe24c04521c7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ccner': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
