{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.merge_json import merge_datasets\n",
    "\n",
    "datasets = [\"data/SuperNER/pre_train.json\",\"data/lebert/dataset/NER/note4/train.json\"]\n",
    "\n",
    "merge_datasets(datasets,\"data/SuperNER_note4/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.merge_json import merge_labels\n",
    "\n",
    "labels = [\"data/weibo/labels.txt\",\"data/SuperNER/tags_list.txt\",\"data/lebert/dataset/NER/note4/labels.txt\"]\n",
    "\n",
    "merge_labels(labels,\"data/SuperNER_note4/labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练预测模型\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': 'data/SuperNER_note4/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/SuperNER_note4/labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'le_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'super_predict_model'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate data/SuperNER_note4/train.json etag: 100%|██████████| 63.6M/63.6M [00:00<00:00, 350MB/s]\n",
      "calculate ./data/weibo/dev.json etag: 100%|██████████| 180k/180k [00:00<00:00, 290MB/s]\n",
      "calculate ./data/weibo/test.json etag: 100%|██████████| 184k/184k [00:00<00:00, 227MB/s]\n",
      "calculate data/SuperNER_note4/labels.txt etag: 100%|██████████| 656/656 [00:00<00:00, 1.29MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"use_gpu\": false,\n",
      "    \"loader_name\": \"le_loader\",\n",
      "    \"model_name\": \"LEBert\",\n",
      "    \"lstm_crf_model_file\": \"save_model/super_predict_model/lstm_crf/lstm_crf_66930.pth\",\n",
      "    \"bert_model_file\": \"save_model/super_predict_model/LEBert/LEBert_66930.pth\",\n",
      "    \"hidden_dim\": 300,\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"bert_config_file_name\": \"./model/chinese_wwm_ext/config.json\",\n",
      "    \"tag_file\": \"data/SuperNER_note4/labels.txt\",\n",
      "    \"padding_length\": 512,\n",
      "    \"num_gpus\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ]\n",
      "}\n",
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 512,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"data/SuperNER_note4/train.json\",\n",
      "    \"eval_file\": \"./data/weibo/dev.json\",\n",
      "    \"test_file\": \"./data/weibo/test.json\",\n",
      "    \"tag_file\": \"data/SuperNER_note4/labels.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": true,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": true,\n",
      "    \"task_name\": \"super_predict_model\"\n",
      "}\n",
      "load cached ./temp/fd9e98e1c863940b44847ce99befeefd-13_09aa1aaf832ce26fdd3856a1e9efec4a_80b03b9eb036cba8e85f623155e5f057_8e491a39483f5e4a1297a94373770eb2/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/fd9e98e1c863940b44847ce99befeefd-13_09aa1aaf832ce26fdd3856a1e9efec4a_80b03b9eb036cba8e85f623155e5f057_8e491a39483f5e4a1297a94373770eb2/1000000/matched_words\n",
      "load cached ./temp/fd9e98e1c863940b44847ce99befeefd-13_09aa1aaf832ce26fdd3856a1e9efec4a_80b03b9eb036cba8e85f623155e5f057_8e491a39483f5e4a1297a94373770eb2/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/SuperNER_note4/labels.txt: 79L [00:00, 576260.90L/s]\n",
      "build line mapper: 79L [00:00, 536165.07L/s]\n",
      "load vocab from files: 100%|██████████| 79/79 [00:00<00:00, 21514.84it/s]\n",
      "load vocab from list: 100%|██████████| 78/78 [00:00<00:00, 437959.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/fd9e98e1c863940b44847ce99befeefd-13_09aa1aaf832ce26fdd3856a1e9efec4a_80b03b9eb036cba8e85f623155e5f057_8e491a39483f5e4a1297a94373770eb2/1000000/vocab_embedding\n",
      "Load pretrained embedding from file.........\n"
     ]
    }
   ],
   "source": [
    "# weibo train.json\n",
    "from CC.predicter import NERPredict\n",
    "import json\n",
    "\n",
    "args[\"lstm_crf_model_file\"] = \"save_model/super_predict_model/lstm_crf/lstm_crf_66930.pth\"\n",
    "args[\"bert_model_file\"] = \"save_model/super_predict_model/LEBert/LEBert_66930.pth\"\n",
    "predict = NERPredict(**args)\n",
    "\n",
    "filename = \"data/weibo/train.json\"\n",
    "\n",
    "batch_size = 64\n",
    "index = 0\n",
    "sentences = []\n",
    "\n",
    "with open(\"data/weibo/train_super.json\", \"w\", encoding=\"utf-8\") as out:\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            text = data[\"text\"]\n",
    "            \n",
    "            sentences.append(text)\n",
    "            index += 1\n",
    "            if index % batch_size == batch_size-1:\n",
    "                for s, label in predict(sentences):\n",
    "                    assert len(s[:args[\"max_seq_length\"]-2])==len(label)\n",
    "                    out.write(f\"\"\"{json.dumps({\"text\":s[:args[\"max_seq_length\"]-2],\"label\":label},ensure_ascii=False)}\\n\"\"\")\n",
    "                sentences = []\n",
    "                out.flush()\n",
    "        if len(sentences)>0:\n",
    "            for s, label in predict(sentences):\n",
    "                assert len(s[:args[\"max_seq_length\"]])==len(label)\n",
    "                out.write(f\"\"\"{json.dumps({\"text\":s[:args[\"max_seq_length\"]-2],\"label\":label},ensure_ascii=False)}\\n\"\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9627571863819468058fb8a0d45e3ad069ccb5b5ca291368ca8fe24c04521c7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ccner': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
