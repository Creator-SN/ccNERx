{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 验证SuperNER_note4是否与验证集有交集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取SuperNER_note4的内容\n",
    "from typing import Set\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "origins:Set[str] = set()\n",
    "with open(\"data/SuperNER_note4/train.json\",\"r\",encoding=\"utf-8\") as reader:\n",
    "    for line in reader:\n",
    "        data = json.loads(line.strip())\n",
    "        text = ''.join(data[\"text\"])\n",
    "        origins.add(text)\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "print(len(origins))\n",
    "\n",
    "# 读取weibo 验证集的类型\n",
    "with open(\"data/weibo/dev.json\",\"r\",encoding=\"utf-8\") as weibo:\n",
    "    for line in tqdm(weibo):\n",
    "        data = json.loads(line.strip())\n",
    "        text = \"\".join(data[\"text\"])\n",
    "        for l in origins:\n",
    "            if (l.startswith(text) or text.startswith(l)) and len(l)>10 and len(text)>10:\n",
    "                cnt+=1\n",
    "                print(text,l)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：构造的超集不包含weibo数据验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集构造步骤，使用main分支\n",
    "1. 使用main分支LeBert训练模型，数据集采用`data/SuperNER_note4/train.json`,标签采用weibo超集标签`data/SuperNER_note4/labels.txt`\n",
    "2. 使用该模型预测weibo `data/weibo/train.json`生成数据`data/weibo/train_super.json`\n",
    "\n",
    "#### 预训练，使用LTS_Prompt_Enhanced分支\n",
    "1. 采用`data/weibo/train_super.json`进行PTV预训练\n",
    "2. 使用预训练模型，通过`data/weibo/train.json`PTV进行fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换分支\n",
    "!git checkout main\n",
    "# 合并数据\n",
    "from tools.merge_json import merge_datasets\n",
    "\n",
    "# 将note4和SuperNER的数据合并在一起\n",
    "datasets = [\"data/SuperNER/pre_train.json\",\"data/lebert/dataset/NER/note4/train.json\"]\n",
    "\n",
    "merge_datasets(datasets,\"data/SuperNER_note4/train.json\")\n",
    "\n",
    "# 合并标签\n",
    "from tools.merge_json import merge_labels\n",
    "\n",
    "labels = [\"data/weibo/labels.txt\",\"data/SuperNER/tags_list.txt\",\"data/lebert/dataset/NER/note4/labels.txt\"]\n",
    "\n",
    "merge_labels(labels,\"data/SuperNER_note4/labels.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeBert Fine-Tune\n",
    "# 训练预测模型\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': 'data/SuperNER_note4/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/SuperNER_note4/labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'le_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'super_predict_model'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测Train.json\n",
    "# weibo train.json\n",
    "from CC.predicter import NERPredict\n",
    "import json\n",
    "\n",
    "# 使用了预训练模型\n",
    "args[\"lstm_crf_model_file\"] = \"save_model/super_predict_model/lstm_crf/lstm_crf_66930.pth\"\n",
    "args[\"bert_model_file\"] = \"save_model/super_predict_model/LEBert/LEBert_66930.pth\"\n",
    "predict = NERPredict(**args)\n",
    "\n",
    "filename = \"data/weibo/train.json\"\n",
    "\n",
    "batch_size = 64\n",
    "index = 0\n",
    "sentences = []\n",
    "\n",
    "with open(\"data/weibo/train_super.json\", \"w\", encoding=\"utf-8\") as out:\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            text = data[\"text\"]\n",
    "            \n",
    "            sentences.append(text)\n",
    "            index += 1\n",
    "            if index % batch_size == batch_size-1:\n",
    "                for s, label in predict(sentences):\n",
    "                    assert len(s[:args[\"max_seq_length\"]-2])==len(label)\n",
    "                    out.write(f\"\"\"{json.dumps({\"text\":s[:args[\"max_seq_length\"]-2],\"label\":label},ensure_ascii=False)}\\n\"\"\")\n",
    "                sentences = []\n",
    "                out.flush()\n",
    "        if len(sentences)>0:\n",
    "            for s, label in predict(sentences):\n",
    "                assert len(s[:args[\"max_seq_length\"]])==len(label)\n",
    "                out.write(f\"\"\"{json.dumps({\"text\":s[:args[\"max_seq_length\"]-2],\"label\":label},ensure_ascii=False)}\\n\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PTV 训练(LTS分支)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git 切换到LTS分支\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train_super.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/data/SuperNER_note4/labels.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'weibo_multiple_pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"NR\": \"人名\",\n",
    "        \"NS\": \"地名\",\n",
    "        \"NT\": \"组织机构\",\n",
    "        \"CONT\": \"国家\",\n",
    "        \"PRO\": \"职位\",\n",
    "        \"RACE\": \"种族\",\n",
    "        \"TITLE\": \"工作名称\",\n",
    "        \"EDU\": \"教育经历\",\n",
    "        \"NAME\": \"名字\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"GPE\": \"政治实体\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\",\n",
    "        \"NORP\": \"政体民族\",\n",
    "        \"PERSON\": \"人名\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer():\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fint-Tune\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': '.save_pretrained/weibo_multiple_pretrained/Bert_5915/pytorch_model.bin',\n",
    "    'prompt_pretrained_file_name': 'save_pretrained/weibo_multiple_pretrained/Bert_5915/pytorch_model.bin',\n",
    "    'prompt_config_file_name': 'save_pretrained/weibo_multiple_pretrained/Bert_5915/config.json',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'ft_loader_v4',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 32,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"NR\": \"人名\",\n",
    "        \"NS\": \"地名\",\n",
    "        \"NT\": \"组织机构\",\n",
    "        \"CONT\": \"国家\",\n",
    "        \"PRO\": \"职位\",\n",
    "        \"RACE\": \"种族\",\n",
    "        \"TITLE\": \"工作名称\",\n",
    "        \"EDU\": \"教育经历\",\n",
    "        \"NAME\": \"名字\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"GPE\": \"政治实体\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\",\n",
    "        \"NORP\": \"政体民族\",\n",
    "        \"PERSON\": \"人名\",\n",
    "    },\n",
    "    'task_name': 'weibo_tag_multiple_3'\n",
    "}\n",
    "\n",
    "from CC.enhanced_trainer import EnhancedNERTrainer\n",
    "trainer = EnhancedNERTrainer(**args)\n",
    "\n",
    "for _ in trainer(lr2=1e-2):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9627571863819468058fb8a0d45e3ad069ccb5b5ca291368ca8fe24c04521c7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ccner': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
