{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from CC.predicter import NERPredict\n",
    "from CC.trainer import NERTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune 参数设置\n",
    "\n",
    "适用于**le_loader**下的fine-tune任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'le_loader',\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'weibo'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数微调\n",
    "\n",
    "调整`Pretrained`和`task name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['pretrained_file_name'] = './save_pretrained/Weibo_Super1x_Pretrained/Bert_2550/pytorch_model.bin'\n",
    "args['train_file'] = './data/ontonotes5_s/train_02_1.json'\n",
    "args['eval_file'] = './data/ontonotes5_s/dev.json'\n",
    "args['test_file'] = './data/ontonotes5_s/test.json'\n",
    "args['tag_file'] = './data/ontonotes5_s/labels.txt'\n",
    "args['batch_size'] = 32\n",
    "args['task_name'] = 'ontonotes5_s_02_p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEBert Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune 参数设置\n",
    "\n",
    "适用于**le_loader**下的fine-tune任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from CC.predicter import NERPredict\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "# %%\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'bert_pretrain_path': './model/chinese_wwm_ext/',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/ontonotes5/train.json',\n",
    "    'eval_file': './data/ontonotes5/dev.json',\n",
    "    'test_file': './data/ontonotes5/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ontonotes5/ontonotes5_labels.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'ft_loader_v1',\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"tag_embedding_file\":\"./data/tencent/label_embedding.txt\",\n",
    "    \"external_entities_file\": \"./data/ontonotes5_s/entities_data_label.json\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'PLEBert',\n",
    "    \"tag_rules\": {\n",
    "        \"LOC\": \"地名\",\n",
    "        \"NORP\": \"政体,民族或宗教\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"GPE\": \"政体\",\n",
    "        \"PERSON\": \"人名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"NR\":\"人名\",\n",
    "        \"NS\":\"地名\",\n",
    "        \"NT\":\"组织机构\",\n",
    "        \"CONT\": \"国家\",\n",
    "        \"PRO\":\"职位\",\n",
    "        \"RACE\":\"种族\",\n",
    "        \"TITLE\":\"工作名称\",\n",
    "        \"EDU\":\"教育经历\",\n",
    "        \"NAME\":\"名字\",\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    },\n",
    "    'task_name': 'weibo'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数微调\n",
    "\n",
    "调整`Pretrained`和`task name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['pretrained_file_name'] = './model/chinese_wwm_ext/pytorch_model.bin'\n",
    "args['train_file'] = './data/ontonotes5_s/train_02_1.json'\n",
    "args['eval_file'] = './data/ontonotes5_s/dev.json'\n",
    "args['test_file'] = './data/ontonotes5_s/test.json'\n",
    "args['tag_file'] = './data/ontonotes5_s/labels.txt'\n",
    "args['batch_size'] = 32\n",
    "args['task_name'] = 'ontonotes5_s_02_pc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/ontonotes5_s/train_02_1.json etag: 100%|██████████| 1.24M/1.24M [00:00<00:00, 22.9MB/s]\n",
      "calculate ./data/ontonotes5_s/dev.json etag: 100%|██████████| 2.53M/2.53M [00:00<00:00, 65.6MB/s]\n",
      "calculate ./data/ontonotes5_s/test.json etag: 100%|██████████| 2.51M/2.51M [00:00<00:00, 315MB/s]\n",
      "calculate ./data/ontonotes5_s/labels.txt etag: 100%|██████████| 110/110 [00:00<00:00, 6.64kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 32,\n",
      "    \"eval_batch_size\": 512,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/ontonotes5_s/train_02_1.json\",\n",
      "    \"eval_file\": \"./data/ontonotes5_s/dev.json\",\n",
      "    \"test_file\": \"./data/ontonotes5_s/test.json\",\n",
      "    \"tag_file\": \"./data/ontonotes5_s/labels.txt\",\n",
      "    \"tag_embedding_file\": \"./data/tencent/label_embedding.txt\",\n",
      "    \"bert_pretrain_path\": \"./model/chinese_wwm_ext/\",\n",
      "    \"external_entities_file\": \"./data/ontonotes5_s/entities_data_label.json\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"max_label_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"lexicon_tree_cache_path\": null,\n",
      "    \"word_vacab_cache_path\": null,\n",
      "    \"task_name\": \"ontonotes5_s_02_pc\",\n",
      "    \"tag_rules\": {\n",
      "        \"LOC\": \"地名\",\n",
      "        \"NORP\": \"政体,民族或宗教\",\n",
      "        \"ORG\": \"机构\",\n",
      "        \"GPE\": \"政体\",\n",
      "        \"PERSON\": \"人名\",\n",
      "        \"PER\": \"人名\",\n",
      "        \"NR\": \"人名\",\n",
      "        \"NS\": \"地名\",\n",
      "        \"NT\": \"组织机构\",\n",
      "        \"CONT\": \"国家\",\n",
      "        \"PRO\": \"职位\",\n",
      "        \"RACE\": \"种族\",\n",
      "        \"TITLE\": \"工作名称\",\n",
      "        \"EDU\": \"教育经历\",\n",
      "        \"NAME\": \"名字\",\n",
      "        \"PER.NOM\": \"指代人名\",\n",
      "        \"LOC.NAM\": \"地名\",\n",
      "        \"PER.NAM\": \"人名\",\n",
      "        \"GPE.NAM\": \"政体\",\n",
      "        \"ORG.NAM\": \"机构\",\n",
      "        \"ORG.NOM\": \"指代机构\",\n",
      "        \"LOC.NOM\": \"指代地名\",\n",
      "        \"GPE.NOM\": \"指代政体\",\n",
      "        \"Time\": \"时间\",\n",
      "        \"Thing\": \"物品\",\n",
      "        \"Metric\": \"度量\",\n",
      "        \"Abstract\": \"作品\",\n",
      "        \"Physical\": \"实体\",\n",
      "        \"Term\": \"术语\",\n",
      "        \"company\": \"企业\",\n",
      "        \"name\": \"名字\",\n",
      "        \"game\": \"游戏\",\n",
      "        \"movie\": \"电影\",\n",
      "        \"position\": \"职位\",\n",
      "        \"address\": \"地址\",\n",
      "        \"government\": \"政府\",\n",
      "        \"scene\": \"景点\",\n",
      "        \"book\": \"书名\"\n",
      "    },\n",
      "    \"debug\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "count line size ./data/tencent/tencent_vocab.txt: 8824306L [00:00, 23928427.69L/s]\n",
      "build line mapper: 8824306L [00:03, 2543916.97L/s]\n",
      "load vocabs into trie: 100%|██████████| 1000000/1000000 [00:13<00:00, 73957.53it/s]\n",
      "build trie: 100%|██████████| 1000000/1000000 [00:13<00:00, 74689.90it/s]\n",
      "count line size ./data/ontonotes5_s/train_02_1.json: 3132L [00:00, 1630857.87L/s]\n",
      "load dataset matched word: 100%|█████████▉| 3131/3132 [00:00<00:00, 7986.49it/s]\n",
      "count line size ./data/ontonotes5_s/dev.json: 4302L [00:00, 1174732.80L/s]\n",
      "load dataset matched word: 100%|█████████▉| 4301/4302 [00:00<00:00, 5157.05it/s]\n",
      "count line size ./data/ontonotes5_s/test.json: 4301L [00:00, 1192471.01L/s]\n",
      "load dataset matched word: 100%|█████████▉| 4300/4301 [00:00<00:00, 5314.40it/s]\n",
      "load vocab from list: 100%|██████████| 78679/78679 [00:00<00:00, 707145.62it/s]\n",
      "count line size ./data/tencent/label_embedding.txt: 39L [00:00, 79950.08L/s]\n",
      "build line mapper: 39L [00:00, 45274.80L/s]\n",
      "load vocab from files: 100%|██████████| 38/38 [00:00<00:00, 8795.52it/s]\n",
      "load vocab from list: 100%|██████████| 37/37 [00:00<00:00, 222016.09it/s]\n",
      "generate label embedding: 100%|██████████| 78686/78686 [04:09<00:00, 314.77it/s]\n",
      "count line size ./data/ontonotes5_s/labels.txt: 18L [00:00, 163414.44L/s]\n",
      "build line mapper: 18L [00:00, 20959.88L/s]\n",
      "load vocab from files: 100%|██████████| 18/18 [00:00<00:00, 3624.98it/s]\n",
      "load vocab from list: 100%|██████████| 17/17 [00:00<00:00, 190141.78it/s]\n",
      "count line size ./data/tencent/word_embedding.txt: 8824332L [00:42, 205547.15L/s]\n",
      "build line mapper: 8824332L [00:42, 208885.42L/s]\n",
      "load word embedding...:   1%|          | 6379/1000000 [00:42<1:03:45, 259.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.073052', '-0.454791', '-0.136675', '0.258515', '0.011885', '0.041317', '0.041896', '0.128609', '-0.163152', '0.246874', '0.092835', '-0.126660', '0.178079', '-0.286865', '0.027544', '-0.119339', '-0.007087', '-0.189252', '0.377924', '0.023270', '-0.367283', '-0.070051', '0.030247', '0.319996', '0.058990', '0.139447', '-0.126480', '0.268859', '-0.023930', '0.227637', '0.044645', '0.301265', '-0.234713', '0.074171', '-0.306097', '-0.403798', '0.140713', '-0.101598', '0.047656', '-0.276438', '-0.080730', '0.143143', '0.189617', '0.129756', '0.185805', '0.133780', '-0.318322', '-0.483692', '0.408157', '0.031308', '-0.311013', '0.059570', '-0.224590', '0.414112', '0.384909', '-0.305530', '0.131048', '0.119147', '0.059128', '-0.248051', '-0.138340', '-0.000503', '-0.100918', '0.304257', '-0.368741', '0.131073', '-0.237684', '-0.029870', '-0.244446', '-0.151965', '-0.221822', '0.489918', '0.114530', '0.175746', '-0.040124', '-0.295019', '-0.063676', '0.157994', '-0.011577', '-0.144796', '0.072814', '0.670234', '0.158069', '0.444338', '0.187207', '-0.178194', '0.441387', '-0.113229', '-0.311998', '-0.262850', '0.166731', '-0.074662', '-0.120234', '-0.557770', '0.217205', '-0.100354', '-0.315967', '-0.199034', '0.044077', '0.072797', '-0.041775', '0.057079', '0.252978', '0.155448', '-0.151973', '0.304786', '0.286322', '-0.461290', '-0.391043', '-0.356367', '0.050163', '-0.301053', '-0.258514', '0.085645', '0.219664', '-0.164307', '0.024513', '-0.077458', '-0.200825', '-0.418520', '0.258938', '-0.140829', '0.152272', '0.176600', '0.340460', '0.357031', '-0.039533', '0.113248', '0.152953', '-0.136520', '-0.167888', '-0.033082', '0.532537', '-0.086386', '-0.234421', '-0.337486', '-0.016323', '-0.018524', '-0.000276', '-0.252389', '-0.395252', '-0.324214', '-0.259109', '0.308163', '0.353517', '-0.195429', '0.319425', '-0.014722', '0.196231', '0.051138', '-0.161133', '-0.056247', '0.262345', '-0.192682', '0.272561', '0.010028', '0.139295', '-0.224138', '0.507957', '0.109516', '0.273037', '0.105556', '-0.182561', '0.069247', '0.102232', '-0.009683', '-0.127744', '0.224196', '-0.027222', '-0.057221', '0.096212', '0.126842', '-0.309821', '-0.031813', '0.135091', '-0.046443', '0.000263', '0.098762', '0.394687', '-0.081866', '0.021604', '0.033224', '-0.121693', '0.001640', '-0.080564', '0.109319', '-0.128558', '0.327593', '0.000599', '0.335171', '0.104823', '0.229730', '0.158929', '-0.203982', '0.355367', '0.507303', '-0.173355', '-0.388700', '-0.324610', '0.296036'] embedding error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load word embedding...: 100%|██████████| 1000000/1000000 [01:12<00:00, 13790.54it/s]\n",
      "load vocab embedding: 78686it [00:06, 13017.37it/s]\n",
      "count line size ./data/ontonotes5_s/train_02_1.json: 3132L [00:00, 1692855.69L/s]\n",
      "load dataset from ./data/ontonotes5_s/train_02_1.json: 100%|█████████▉| 3131/3132 [00:04<00:00, 729.57it/s]\n",
      "count line size ./data/ontonotes5_s/dev.json: 4302L [00:00, 1061093.55L/s]\n",
      "load dataset from ./data/ontonotes5_s/dev.json: 100%|█████████▉| 4301/4302 [00:09<00:00, 460.90it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super NER的Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from CC.predicter import NERPredict\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "# %%\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/Super_x_Ontonotes5/pre_train_0.2x.json',\n",
    "    'eval_file': './data/Super_x_Ontonotes5/pre_dev.json',\n",
    "    'test_file': './data/Super_x_Ontonotes5/pre_dev.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/Super_x_Ontonotes5/tags_list.txt',\n",
    "    'output_eval': True,\n",
    "    'loader_name': 'le_loader',\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'do_shuffle': True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'super_x_ontonotes'\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2, resume_path='./save_model/super_x_ontonotes', resume_step=2586):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super NER的预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1500000,\n",
    "    'train_file': './data/SuperNER/pre_train.json',\n",
    "    'eval_file': './data/SuperNER/pre_dev.json',\n",
    "    'test_file': './data/SuperNER/pre_test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/SuperNER/tags_list.txt',\n",
    "    'loader_name': 'lex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Pre_trained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weibo的预训练\n",
    "loader: lex_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'lex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Weibo_Full_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/dev.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'lex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag_combine.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Ontonotes5_02_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"PRODUCT\": \"产品\",\n",
    "        \"FAC\": \"场地\",\n",
    "        \"ORDINAL\": \"排名\",\n",
    "        \"QUANTITY\": \"无单位数量\",\n",
    "        \"CARDINAL\": \"有单位数量\",\n",
    "        \"EVENT\": \"事件\",\n",
    "        \"MONEY\": \"金额\",\n",
    "        \"DATE\": \"日期\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"WORK_OF_ART\": \"作品\",\n",
    "        \"NORP\": \"政体,民族或宗教\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"PERCENT\": \"百分数\",\n",
    "        \"LANGUAGE\": \"语言\",\n",
    "        \"GPE\": \"政体\",\n",
    "        \"PERSON\": \"人名\",\n",
    "        \"LAW\": \"法文\",\n",
    "        \"TIME\": \"时间\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "args['pretrained_file_name'] = './save_pretrained/Ontonotes5_003_Pretrained/Bert_1290/pytorch_model.bin'\n",
    "args['max_scan_num'] = '1000000'\n",
    "args['train_file'] = './data/ontonotes5/train_003.json'\n",
    "args['eval_file'] = './data/ontonotes5/dev.json'\n",
    "args['test_file'] = './data/ontonotes5/test.json'\n",
    "args['tag_file'] = './data/ontonotes5/ontonotes5_pretrained_labels.txt'\n",
    "args['task_name'] = 'Ontonotes5_003_Pretrained'\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontonote5(Four Labels)的预训练\n",
    "loader: lex_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/dev.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'lex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Ontonotes5_02_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"LOC\": \"地名\",\n",
    "        \"NORP\": \"政体,民族或宗教\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"GPE\": \"政体\",\n",
    "        \"PERSON\": \"人名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "args['pretrained_file_name'] = 'save_pretrained/Ontonotes5_s_02_Pretrained/Bert_1960/pytorch_model.bin'\n",
    "args['max_scan_num'] = '1000000'\n",
    "args['train_file'] = './data/ontonotes5_s/train_02_1.json'\n",
    "args['eval_file'] = './data/ontonotes5_s/dev.json'\n",
    "args['test_file'] = './data/ontonotes5_s/test.json'\n",
    "args['tag_file'] = './data/ontonotes5_s/pretrained_labels_ori.txt'\n",
    "args['task_name'] = 'Ontonotes5_s_02_Pretrained'\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weibo的预训练(屏蔽无关实体)\n",
    "loader: lex_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'lex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Weibo_Full_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"pass_none_rule\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"government\": \"政府\"\n",
    "    }\n",
    "}\n",
    "\n",
    "args['pretrained_file_name'] = './model/chinese_wwm_ext/pytorch_model.bin'\n",
    "args['max_scan_num'] = '1000000'\n",
    "args['train_file'] = './data/weibo/train.json'\n",
    "args['tag_file'] = './data/weibo/pretrained_labels.txt'\n",
    "args['task_name'] = 'Weibo_Full_Pretrained'\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 适用于`CONLL`的预训练\n",
    "loader: cnx_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibonew/train.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'cnx_loader',\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    'use_json': True,\n",
    "    'model_name': 'Bert',\n",
    "    'task_name': 'Weibo_CNX_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"PRODUCT\": \"产品\",\n",
    "        \"FAC\": \"场地\",\n",
    "        \"ORDINAL\": \"排名\",\n",
    "        \"QUANTITY\": \"无单位数量\",\n",
    "        \"CARDINAL\": \"有单位数量\",\n",
    "        \"EVENT\": \"事件\",\n",
    "        \"MONEY\": \"金额\",\n",
    "        \"DATE\": \"日期\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"WORK_OF_ART\": \"作品\",\n",
    "        \"NORP\": \"政体,民族或宗教\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"PERCENT\": \"百分数\",\n",
    "        \"LANGUAGE\": \"语言\",\n",
    "        \"GPE\": \"政体\",\n",
    "        \"PERSON\": \"人名\",\n",
    "        \"LAW\": \"法文\",\n",
    "        \"TIME\": \"时间\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "args['pretrained_file_name'] = './save_pretrained/Ontonotes5_02_Pretrained/Bert_2886/pytorch_model.bin'\n",
    "args['train_file'] = './data/ontonotes5/train_02_1.json'\n",
    "args['tag_file'] = './data/ontonotes5/ontonotes5_pretrained_labels.txt'\n",
    "args['task_name'] = 'Ontonotes5_02_Pretrained'\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weibo 预训练x纠错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from CC.loaders.utils import *\n",
    "import json\n",
    "from CC.pre_trained import NERPreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0, 1, 2, 3],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/weibo/train_5x.json',\n",
    "    'eval_file': './data/weibo/dev.json',\n",
    "    'test_file': './data/weibo/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/weibo/pretrained_labels.txt',\n",
    "    'loader_name': 'labellex_loader',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 32,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'Weibo_Full20xC_Pretrained',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"PER.NOM\": \"指代人名\",\n",
    "        \"LOC.NAM\": \"地名\",\n",
    "        \"PER.NAM\": \"人名\",\n",
    "        \"GPE.NAM\": \"政体\",\n",
    "        \"ORG.NAM\": \"机构\",\n",
    "        \"ORG.NOM\": \"指代机构\",\n",
    "        \"LOC.NOM\": \"指代地名\",\n",
    "        \"GPE.NOM\": \"指代政体\",\n",
    "        \"ORG\": \"机构\",\n",
    "        \"LOC\": \"地名\",\n",
    "        \"PER\": \"人名\",\n",
    "        \"Time\": \"时间\",\n",
    "        \"Thing\": \"物品\",\n",
    "        \"Metric\": \"度量\",\n",
    "        \"Abstract\": \"作品\",\n",
    "        \"Physical\": \"实体\",\n",
    "        \"Term\": \"术语\",\n",
    "        \"company\": \"企业\",\n",
    "        \"name\": \"名字\",\n",
    "        \"game\": \"游戏\",\n",
    "        \"movie\": \"电影\",\n",
    "        \"position\": \"职位\",\n",
    "        \"address\": \"地址\",\n",
    "        \"government\": \"政府\",\n",
    "        \"scene\": \"景点\",\n",
    "        \"book\": \"书名\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.loaders import *\n",
    "\n",
    "loader = LabelLoader(**{\n",
    "    \"auto_loader\": False,\n",
    "    \"debug\": True,\n",
    "    \"file_name\": \"./data/weibo/train.json\",\n",
    "    \"random_rate\": 1.0,\n",
    "    \"expansion_rate\": 5\n",
    "}).read_data_set(\"./data/weibo/train.json\", 1.0) \\\n",
    "    .process_data(5) \\\n",
    "    .to_file(\"./train_5x.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e1e097b6c3c5a2a39328ddbc7de6327b7bd71c15618bc750f041eecacee4167"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pcpower': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
